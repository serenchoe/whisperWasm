<!doctype html>
<html lang="en-us">
    <head>
        <title>stream : Real-time Whisper transcription in WebAssembly</title>

        <style>
            #output {
                width: 100%;
                height: 100%;
                margin: 0 auto;
                margin-top: 10px;
                border-left: 0px;
                border-right: 0px;
                padding-left: 0px;
                padding-right: 0px;
                display: block;
                background-color: black;
                color: white;
                font-size: 10px;
                font-family: 'Lucida Console', Monaco, monospace;
                outline: none;
                white-space: pre;
                overflow-wrap: normal;
                overflow-x: scroll;
            }
        </style>
    </head>
    <body>
        <div id="main-container">
            <b>stream : Real-time Whisper transcription in WebAssembly</b>

            <br><br>

            You can find more about this project on <a href="https://github.com/ggerganov/whisper.cpp/tree/master/examples/stream.wasm">GitHub</a>.

            <br><br>

            <b>More examples:</b>
                <a href="https://stagingpc.view.dhcth.link/">main</a> |
                <a href="https://stagingpc.view.dhcth.link/bench">bench</a> |
                <a href="https://stagingpc.view.dhcth.link/stream">stream</a> |
                <a href="https://stagingpc.view.dhcth.link/command">command</a> |
                <a href="https://stagingpc.view.dhcth.link/talk">talk</a> |

            <br><br>

            <hr>

            Select the model you would like to use, click the "Start" button and start speaking

            <br><br>

            <div id="model-whisper">
                Whisper model: <span id="model-whisper-status"></span>
                <button id="fetch-whisper-tiny-en" onclick="loadWhisper('tiny.en')">tiny.en (75 MB)</button>
                <button id="fetch-whisper-base-en" onclick="loadWhisper('base.en')">base.en (142 MB)</button>
                <br><br>
                Quantized models:<br><br>
                <button id="fetch-whisper-tiny-en-q5_1"   onclick="loadWhisper('tiny-en-q5_1')">tiny.en (Q5_1, 31 MB)</button>
                <button id="fetch-whisper-base-en-q5_1"   onclick="loadWhisper('base-en-q5_1')">base.en (Q5_1, 57 MB)</button>
                <span id="fetch-whisper-progress"></span>

                <!--
                    <input type="file" id="file" name="file" onchange="loadFile(event, 'whisper.bin')" />
                -->
            </div>

            <br>

            <div id="input">
                <button id="start"  onclick="onStart()" disabled>Start</button>
                <button id="stop"   onclick="onStop()" disabled>Stop</button>
                <button id="clear"  onclick="clearCache()">Clear Cache</button>
            </div>

            <br>

            <div id="state">
                Status: <b><span id="state-status">not started</span></b>

                <pre id="state-transcribed">[The transcribed text will be displayed here]</pre>
            </div>

            <hr>

            Debug output:
            <textarea id="output" rows="20"></textarea>

            <br>

            <b>Troubleshooting</b>

            <br><br>

            The page does some heavy computations, so make sure:

            <ul>
                <li>To use a modern web browser (e.g. Chrome, Firefox)</li>
                <li>To use a fast desktop or laptop computer (i.e. not a mobile phone)</li>
                <li>Your browser supports WASM <a href="https://webassembly.org/roadmap/">Fixed-width SIMD</a></li>
            </ul>

            <div class="cell-version">
                <span>
                    |
                    Build time: <span class="nav-link">Tue Aug 29 13:07:16 2023</span> |
                    Commit hash: <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/commit/50bf9ca0">50bf9ca0</a> |
                    Commit subject: <span class="nav-link">2GB window_samples=10sec</span> |
                    <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/tree/master/examples/stream.wasm">Source Code</a> |
                </span>
            </div>
        </div>

        <script type="text/javascript" src="helpers.js"></script>
        <script type='text/javascript'>
            // web audio context
            var context = null;

            // audio data
            var audio = null;
            var audio0 = null;

            // the stream instance
            var instance = null;

            // model name
            var model_whisper = null;

            var Module = {
                print: printTextarea,
                printErr: printTextarea,
                setStatus: function(text) {
                    printTextarea('js: ' + text);
                },
                monitorRunDependencies: function(left) {
                },
                preRun: function() {
                    printTextarea('js: Preparing ...');
                },
                postRun: function() {
                    printTextarea('js: Initialized successfully!');
                }
            };

            //
            // fetch models
            //

            let dbVersion = 1
            let dbName    = 'whisper.ggerganov.com';
            let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB

            function storeFS(fname, buf) {
                // write to WASM file using FS_createDataFile
                // if the file exists, delete it
                try {
                    Module.FS_unlink(fname);
                } catch (e) {
                    // ignore
                }

                Module.FS_createDataFile("/", fname, buf, true, true);

                printTextarea('storeFS: stored model: ' + fname + ' size: ' + buf.length);

                document.getElementById('model-whisper-status').innerHTML = 'loaded "' + model_whisper + '"!';

                if (model_whisper != null) {
                    document.getElementById('start').disabled = false;
                    document.getElementById('stop' ).disabled = true;
                }
            }

            function loadWhisper(model) {
                let urls = {
                    'tiny.en': 'https://stagingpc.view.dhcth.link/ggml-model-whisper-tiny.en.bin',
                    'base.en': 'https://stagingpc.view.dhcth.link/ggml-model-whisper-base.en.bin',

                    'tiny-en-q5_1':  'https://stagingpc.view.dhcth.link/ggml-model-whisper-tiny.en-q5_1.bin',
                    'base-en-q5_1':  'https://stagingpc.view.dhcth.link/ggml-model-whisper-base.en-q5_1.bin',
                };

                let sizes = {
                    'tiny.en': 75,
                    'base.en': 142,

                    'tiny-en-q5_1':   31,
                    'base-en-q5_1':   57,
                };

                let url     = urls[model];
                let dst     = 'whisper.bin';
                let size_mb = sizes[model];

                model_whisper = model;

                document.getElementById('fetch-whisper-tiny-en').style.display = 'none';
                document.getElementById('fetch-whisper-base-en').style.display = 'none';

                document.getElementById('fetch-whisper-tiny-en-q5_1').style.display = 'none';
                document.getElementById('fetch-whisper-base-en-q5_1').style.display = 'none';

                document.getElementById('model-whisper-status').innerHTML = 'loading "' + model + '" ... ';

                cbProgress = function(p) {
                    let el = document.getElementById('fetch-whisper-progress');
                    el.innerHTML = Math.round(100*p) + '%';
                };

                cbCancel = function() {
                    var el;
                    el = document.getElementById('fetch-whisper-tiny-en'); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base-en'); if (el) el.style.display = 'inline-block';

                    el = document.getElementById('fetch-whisper-tiny-en-q5_1'); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base-en-q5_1'); if (el) el.style.display = 'inline-block';

                    el = document.getElementById('model-whisper-status');  if (el) el.innerHTML = '';
                };

                loadRemote(url, dst, size_mb, cbProgress, storeFS, cbCancel, printTextarea);
            }

            //
            // microphone
            //

            const kSampleRate = 16000;
            const kRestartRecording_s = 120;
            const kIntervalAudio_ms = 5000; // pass the recorded audio to the C++ instance at this rate

            var mediaRecorder = null;
            var doRecording = false;
            var startTime = 0;

            window.AudioContext = window.AudioContext || window.webkitAudioContext;
            window.OfflineAudioContext = window.OfflineAudioContext || window.webkitOfflineAudioContext;

            function stopRecording() {
                Module.set_status("paused");
                doRecording = false;
                audio0 = null;
                audio = null;
                context = null;
            }

            function startRecording() {
                if (!context) {
                    context = new AudioContext({
                        sampleRate: kSampleRate,
                        channelCount: 1,
                        echoCancellation: false,
                        autoGainControl:  true,
                        noiseSuppression: true,
                    });
                }

                Module.set_status("");

                document.getElementById('start').disabled = true;
                document.getElementById('stop').disabled = false;

                doRecording = true;
                startTime = Date.now();

                var chunks = [];
                var stream = null;

                var audioContext = null;

                navigator.mediaDevices.getUserMedia({audio: true, video: false})
                    .then(function(s) {
                        stream = s;
                        audioContext = new AudioContext({ sampleRate: 16000 });
                        const sourceNode = audioContext.createMediaStreamSource(s);
                        audioContext.audioWorklet.addModule('captionWhisperAudioWorklet.js').then(() => {
                            try {
                                const processorNode = new AudioWorkletNode(audioContext, 'CaptionsWhisperPcmProcessor', {
                                    // parameterData: { chunkSize: 4096 }
                                    parameterData: { chunkSize: 160000 }
                                });

                                processorNode.port.onmessage = (event) => {
                                    if (event.data.error) {
                                        console.log(`Error processing PCM audio: ${event.data.error}`);
                                    } else {
                                        if (instance) {
                                            const float32array = new Float32Array(event.data.chunk);
                                            Module.set_audio(instance, float32array);
                                        }
                                    }
                                };

                                sourceNode.connect(processorNode);
                                processorNode.connect(audioContext.destination);

                                audioContext.resume().then(() => {
                                    console.log('AudioContext for captioning resumed');
                                });
                            } catch (error) {
                                console.log(`Error setting up audio worklet: ${error}`);
                                return;
                            }
                        })
                    })
                    .catch(function(err) {
                        printTextarea('js: error getting audio stream: ' + err);
                    });

                var interval = setInterval(function() {
                    if (!doRecording) {
                        clearInterval(interval);
                        audioContext.suspend();
                        stream.getTracks().forEach(function(track) {
                            track.stop();
                        });
                        
                        document.getElementById('start').disabled = false;
                        document.getElementById('stop').disabled  = true;

                    }

                    // if audio length is more than kRestartRecording_s seconds, restart recording
                    if (audio != null && audio.length > kSampleRate*kRestartRecording_s) {
                        if (doRecording) {
                            //printTextarea('js: restarting recording');

                            clearInterval(interval);
                            audio0 = audio;
                            audio = null;
                            audioContext.suspend();
                            stream.getTracks().forEach(function(track) {
                                track.stop();
                            });
                        }
                    }
                }, 100);
            }

            //
            // main
            //

            var nLines = 0;
            var intervalUpdate = null;
            var transcribedAll = '';

            function onStart() {
                if (!instance) {
                    instance = Module.init('whisper.bin');

                    if (instance) {
                        printTextarea("js: whisper initialized, instance: " + instance);
                    }
                }

                if (!instance) {
                    printTextarea("js: failed to initialize whisper");
                    return;
                }

                startRecording();

                intervalUpdate = setInterval(function() {
                    var transcribed = Module.get_transcribed();

                    if (transcribed != null && transcribed.length > 1) {
                        transcribedAll += transcribed + '<br>';
                        nLines++;

                        // if more than 10 lines, remove the first line
                        if (nLines > 10) {
                            var i = transcribedAll.indexOf('<br>');
                            if (i > 0) {
                                transcribedAll = transcribedAll.substring(i + 4);
                                nLines--;
                            }
                        }
                    }

                    document.getElementById('state-status').innerHTML = Module.get_status();
                    document.getElementById('state-transcribed').innerHTML = transcribedAll;
                }, 100);
            }

            function onStop() {
                stopRecording();
            }

        </script>
        <script type="text/javascript" src="stream.js"></script>
    </body>
</html>
